{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Experiment Powers\n",
    "This notebook aids in the extraction of powers from the power log files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "POWER_DIR='/home/nsultana'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scanning through power log\n",
    "Pre-processing the power log to grab (approximately) the time that is used for the experiments prevents numpy from having to parse days worth of data, and reduces waiting time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def to_datetime(t):\n",
    "    if isinstance(t, float):\n",
    "        t = pd.to_datetime(t * 1e9).tz_localize('UTC')\n",
    "    if isinstance(t, str):\n",
    "        t = pd.to_datetime(t)\n",
    "    return t\n",
    "\n",
    "def open_at_time(fname, start_time, end_time=None, jump_bytes=64000):\n",
    "    ''' Jumps backwards from the end of the file looking for the first matching timestamps.\n",
    "    File is readable from this location.\n",
    "    If end_time is present, reads the contents between start_time and end_time into a file-like buffer.\n",
    "    '''\n",
    "    # Must open in binary mode to enable .seek to arbitrary locations\n",
    "    f = open(fname, 'rb')\n",
    "    start_time, end_time = to_datetime(start_time), to_datetime(end_time)\n",
    "    \n",
    "    end_loc = None\n",
    "    for i in range(1, 100000):\n",
    "        f.seek(-jump_bytes * i, os.SEEK_END)\n",
    "        firstline = f.readline()\n",
    "        line = f.readline().decode('utf-8')\n",
    "        strtime = ' '.join(line.split(' ')[:2])\n",
    "        curtime = pd.to_datetime(strtime)\n",
    "        if curtime <= start_time:\n",
    "            print(\"Found location in file: %s\"%line)\n",
    "            f.seek(-len(line), 1)\n",
    "            \n",
    "            if end_loc is not None:\n",
    "                rd_size = end_loc - f.tell()\n",
    "                print(\"Reading into buffer\")\n",
    "                sio = StringIO(f.read(rd_size).decode('utf-8'))\n",
    "                print(\"Done.\")\n",
    "                f.close()\n",
    "                return sio\n",
    "            else:\n",
    "                f2 = open(fname, 'r')\n",
    "                f2.seek(f.tell())\n",
    "                f.close()\n",
    "                return f2\n",
    "        if end_time is not None and curtime > end_time:\n",
    "            end_loc  = f.tell()\n",
    "            \n",
    "    print(\"Jumped 1000000 times and still didn't find it\")\n",
    "    f.close()\n",
    "    return open(fname, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the power log\n",
    "Power log is reduced to only the time points at which the power changes.\n",
    "It is cleaned and inserted into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def read_power_log(num, start_time, end_time):\n",
    "    start_time, end_time = to_datetime(start_time), to_datetime(end_time)\n",
    "    fname = os.path.join(POWER_DIR, 'power_%d.out' % num)\n",
    "    f = open_at_time(fname, start_time, end_time)\n",
    "    \n",
    "    # For some reason this is infinitely faster than using read_csv\n",
    "    #     df = pd.read_csv(f, sep=' ', error_bad_lines=True, header=None,\n",
    "    #                      names=['date', 'time', 'device', 'ip', 'power'],\n",
    "    #                      dtype={'device': str, 'ip': str, 'power': str},\n",
    "    #                      date_parser=date_parser,\n",
    "    #                      parse_dates=[[0,1]], infer_datetime_format=True, engine='c',\n",
    "    #                      low_memory=False)\n",
    "    \n",
    "    # Read into a numpy array\n",
    "    arr = np.loadtxt(f, delimiter=' ', dtype=object)\n",
    "    df = pd.DataFrame(arr, columns=['date', 'time', 'device', 'ip', 'power'])\n",
    "    date_time = df.date.astype(object) + ' ' + df.time.astype(object)\n",
    "    df['date_time'] = pd.to_datetime(date_time.astype(str))\n",
    "    del df['date']\n",
    "    del df['time']\n",
    "\n",
    "    # Discard any rows with missing power values\n",
    "    df.power = pd.to_numeric(df.power, errors='coerce')\n",
    "    df = df[~df.power.isna()]\n",
    "    \n",
    "    # Error on power monitors sometimes reports very high power values\n",
    "    df = df[df.power < 10000]\n",
    "    \n",
    "    # Filter based on the provided start time\n",
    "    df = df[df.date_time >= pd.to_datetime(start_time)]\n",
    "    if end_time is not None:\n",
    "        df = df[df.date_time <= pd.to_datetime(end_time)]\n",
    "    print(\"Read %d power values\" % len(df))\n",
    "    \n",
    "    # Reduce to only the time-points where the power changes\n",
    "    df = df[df.power.diff() != 0]\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def read_all_power_logs(n, start_time, end_time=None):\n",
    "    ''' Reads power logs numbered 0:(n-1) '''\n",
    "    out = []\n",
    "    for num in range(n):\n",
    "        out.append(read_power_log(num, start_time, end_time))\n",
    "    out = list(filter(lambda x: len(x) > 1, out))\n",
    "    return out\n",
    "\n",
    "def read_experiments_powers(events_sets, experiments):\n",
    "    ''' events_sets[group][experiment][trial][event]'''\n",
    "    print(experiments)\n",
    "    mintime = min([ev[experiments[0]][0][0]['time_'] for ev in events_sets])\n",
    "    maxtime = max([ev[experiments[-1]][-1][-1]['time_'] for ev in events_sets])\n",
    "    return read_all_power_logs(10, mintime, maxtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling powers during experiment\n",
    "Using shremote logs, powers are combined into a single dataframe with an added `exp_time` column, which gives the amount of elapsed time since the start of the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_LEN = pd.Timedelta(50, 's')\n",
    "\n",
    "def experiment_powers(events, dfs, buff = pd.Timedelta(15, 's')):\n",
    "    starts, ends = [], []\n",
    "    \n",
    "    for exp_events in events:\n",
    "        # NB: Assumes the start of the experiment is the /second/ `tcpreplay` \n",
    "        replay_events = filter(lambda x: x['name_'] == 'tcpreplay', exp_events)\n",
    "        start = list(replay_events)[-1]['time_']\n",
    "        start = pd.to_datetime(start * 1e9).tz_localize('UTC') - buff\n",
    "        starts.append(start)\n",
    "        end = start + EXP_LEN + buff * 2\n",
    "        ends.append(end)\n",
    "        \n",
    "    minstart = min(starts)\n",
    "    maxend = max(ends)\n",
    "        \n",
    "    dfs_exp = []\n",
    "    for df in dfs:\n",
    "        df = df[(df.date_time > minstart) & (df.date_time < maxend)]\n",
    "        for i, (start, end) in enumerate(zip(starts, ends)):\n",
    "            dfi = df[(df.date_time > start) & (df.date_time < end)]\n",
    "            dfi = dfi[dfi.power < 1e3]\n",
    "            dfi = dfi.reset_index(drop=True)\n",
    "            dfi['exp_time'] = (dfi.date_time - start - buff).apply(lambda x: x.total_seconds())\n",
    "            dfi.date_time -= start\n",
    "            dfi[\"trial\"] = i\n",
    "            dfs_exp.append(dfi)\n",
    "    return pd.concat(dfs_exp, ignore_index=True)\n",
    "\n",
    "def all_experiment_powers(events, powers, buff = pd.Timedelta(15, 'seconds')):\n",
    "    all_dfs = []\n",
    "    for exp, events in events.items():\n",
    "        print(\"Read\", exp)\n",
    "        df = experiment_powers(events, powers)\n",
    "        df['experiment'] = exp\n",
    "        all_dfs.append(df)\n",
    "    return pd.concat(all_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading experiment logs\n",
    "Need to read the timestamps associated with the experiments to load and label the right data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "EXPERIMENTS = ['baseline', 'hc', 'drop', 'fec', 'kv']\n",
    "\n",
    "def load_experiment_events(exp, n, base_dir):\n",
    "    ''' Loads experiments 1:n labeled `exp` in directory `base_dir` '''\n",
    "    events = []\n",
    "    for i in range(1, n+1):\n",
    "        exp_file = os.path.join(base_dir, exp, '%s_%d' % (exp, i), 'event_log.json')\n",
    "        with open(exp_file) as f:\n",
    "            events.append(json.load(f))\n",
    "    return events\n",
    "\n",
    "def load_events(base_dir, n=10, experiments=EXPERIMENTS):\n",
    "    events = {}\n",
    "    for exp in experiments:\n",
    "        exp_events = load_experiment_events(exp, n, base_dir)\n",
    "        events[exp] = exp_events\n",
    "    return events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess and save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "POWER_SAVE_DIR = '.'\n",
    "def save_experiment_powers(base_dirs, n=10, experiments=EXPERIMENTS):\n",
    "    events = {}\n",
    "    for label, base_dir in base_dirs.items():\n",
    "        events[label] = load_events(base_dir, n, experiments)\n",
    "       \n",
    "    powers = read_experiments_powers(events.values(), experiments)\n",
    "    \n",
    "    exps_powers = {}\n",
    "    for label, exp_events in events.items():\n",
    "        exp_powers = all_experiment_powers(exp_events, powers)\n",
    "        exp_powers.to_pickle(os.path.join(POWER_SAVE_DIR, '%s.pickle' % label))\n",
    "        exps_powers[label] = exp_powers\n",
    "    return exps_powers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiment_powers(label):\n",
    "    return pd.read_pickle(os.path.join(POWER_SAVE_DIR, '%s.pickle' % label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['baseline', 'hc', 'drop', 'fec', 'kv']\n",
      "Found location in file: 2019-08-21 03:06:10.021598157+00:00 fpga12/1 (192.168.1.115): 27.125\n",
      "\n",
      "Reading into buffer\n",
      "Done.\n",
      "Read 170849 power values\n",
      "Found location in file: 2019-08-11 23:27:30.834352528+00:00 dcomp1 (192.168.1.108): 106.155\n",
      "\n",
      "Read 0 power values\n",
      "Found location in file: 2019-08-21 03:06:47.541570991+00:00 tofino (192.168.1.117): 111.090\n",
      "\n",
      "Reading into buffer\n",
      "Done.\n",
      "Read 170994 power values\n",
      "Found location in file: 2019-08-21 03:07:32.194541658+00:00 tclust2 (192.168.1.111): 123.170\n",
      "\n",
      "Reading into buffer\n",
      "Done.\n",
      "Read 169648 power values\n",
      "Found location in file: 2019-08-21 03:07:41.781920569+00:00 tclust4 (192.168.1.114): 104.290\n",
      "\n",
      "Reading into buffer\n",
      "Done.\n",
      "Read 209326 power values\n",
      "Found location in file: 2019-08-21 03:08:04.999408168+00:00 fpga12/2 (192.168.1.113): 26.225\n",
      "\n",
      "Reading into buffer\n",
      "Done.\n",
      "Read 170918 power values\n",
      "Found location in file: 2019-08-21 03:07:08.867241037+00:00 fpga13/0 (192.168.1.105): 26.980\n",
      "\n",
      "Reading into buffer\n",
      "Done.\n",
      "Read 171665 power values\n",
      "Found location in file: 2019-08-21 03:06:28.736862858+00:00 fpga13/1 (192.168.1.104): 25.710\n",
      "\n",
      "Reading into buffer\n",
      "Done.\n",
      "Read 172028 power values\n",
      "Found location in file: 2019-08-21 03:08:27.686437694+00:00 fpga12/0 (192.168.1.110): 25.030\n",
      "\n",
      "Reading into buffer\n",
      "Done.\n",
      "Read 171208 power values\n",
      "Found location in file: 2019-08-21 03:06:46.549466071+00:00 arista (192.168.1.118): 107.680\n",
      "\n",
      "Reading into buffer\n",
      "Done.\n",
      "Read 170950 power values\n",
      "Read baseline\n",
      "Read hc\n",
      "Read drop\n",
      "Read fec\n",
      "Read kv\n",
      "Read baseline\n",
      "Read hc\n",
      "Read drop\n",
      "Read fec\n",
      "Read kv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fpga':          device                ip    power       date_time   exp_time  trial  \\\n",
       " 0      fpga12/1  (192.168.1.115):   27.110 00:00:01.762563 -13.237437      0   \n",
       " 1      fpga12/1  (192.168.1.115):   27.105 00:00:02.810665 -12.189334      0   \n",
       " 2      fpga12/1  (192.168.1.115):   27.115 00:00:03.685390 -11.314609      0   \n",
       " 3      fpga12/1  (192.168.1.115):   27.130 00:00:04.732500 -10.267500      0   \n",
       " 4      fpga12/1  (192.168.1.115):   27.125 00:00:05.839482  -9.160517      0   \n",
       " ...         ...               ...      ...             ...        ...    ...   \n",
       " 32226    arista  (192.168.1.118):  109.395 00:01:10.025621  55.025621      9   \n",
       " 32227    arista  (192.168.1.118):  109.285 00:01:11.076213  56.076213      9   \n",
       " 32228    arista  (192.168.1.118):  109.160 00:01:12.112506  57.112507      9   \n",
       " 32229    arista  (192.168.1.118):  109.090 00:01:12.992435  57.992436      9   \n",
       " 32230    arista  (192.168.1.118):  109.060 00:01:14.034746  59.034747      9   \n",
       " \n",
       "       experiment  \n",
       " 0       baseline  \n",
       " 1       baseline  \n",
       " 2       baseline  \n",
       " 3       baseline  \n",
       " 4       baseline  \n",
       " ...          ...  \n",
       " 32226         kv  \n",
       " 32227         kv  \n",
       " 32228         kv  \n",
       " 32229         kv  \n",
       " 32230         kv  \n",
       " \n",
       " [32231 rows x 7 columns],\n",
       " 'tofino':          device                ip    power       date_time   exp_time  trial  \\\n",
       " 0      fpga12/1  (192.168.1.115):   27.090 00:00:00.542285 -14.457715      0   \n",
       " 1      fpga12/1  (192.168.1.115):   27.100 00:00:01.592744 -13.407256      0   \n",
       " 2      fpga12/1  (192.168.1.115):   27.110 00:00:02.687717 -12.312283      0   \n",
       " 3      fpga12/1  (192.168.1.115):   27.115 00:00:03.707803 -11.292196      0   \n",
       " 4      fpga12/1  (192.168.1.115):   27.120 00:00:04.592197 -10.407802      0   \n",
       " ...         ...               ...      ...             ...        ...    ...   \n",
       " 32204    arista  (192.168.1.118):  108.860 00:01:15.887427  60.887427      9   \n",
       " 32205    arista  (192.168.1.118):  108.980 00:01:16.938932  61.938932      9   \n",
       " 32206    arista  (192.168.1.118):  109.125 00:01:18.017038  63.017038      9   \n",
       " 32207    arista  (192.168.1.118):  109.210 00:01:19.081861  64.081862      9   \n",
       " 32208    arista  (192.168.1.118):  109.350 00:01:19.975825  64.975825      9   \n",
       " \n",
       "       experiment  \n",
       " 0       baseline  \n",
       " 1       baseline  \n",
       " 2       baseline  \n",
       " 3       baseline  \n",
       " 4       baseline  \n",
       " ...          ...  \n",
       " 32204         kv  \n",
       " 32205         kv  \n",
       " 32206         kv  \n",
       " 32207         kv  \n",
       " 32208         kv  \n",
       " \n",
       " [32209 rows x 7 columns]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_experiment_powers(dict(\n",
    "    fpga = 'data/e2e_output_500k_fpga_hc_11',\n",
    "    tofino = 'data/e2e_output_500k_tofino_hc_11'\n",
    "));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['baseline', 'hc']\n",
      "Found location in file: 2019-08-27 17:52:01.548115960+00:00 fpga12/1 (192.168.1.115): 27.160\n",
      "\n",
      "Reading into buffer\n",
      "Done.\n",
      "Read 28264 power values\n",
      "Found location in file: 2019-08-11 23:27:30.834352528+00:00 dcomp1 (192.168.1.108): 106.155\n",
      "\n",
      "Read 0 power values\n",
      "Found location in file: 2019-08-27 17:52:14.190235602+00:00 tofino (192.168.1.117): 110.380\n",
      "\n",
      "Reading into buffer\n",
      "Done.\n",
      "Read 28305 power values\n",
      "Found location in file: 2019-08-27 17:51:34.869971898+00:00 tclust2 (192.168.1.111): 121.060\n",
      "\n",
      "Reading into buffer\n",
      "Done.\n",
      "Read 27644 power values\n",
      "Found location in file: 2019-08-27 17:52:53.556819522+00:00 tclust4 (192.168.1.114): 115.265\n",
      "\n",
      "Reading into buffer\n",
      "Done.\n",
      "Read 34348 power values\n",
      "Found location in file: 2019-08-27 17:51:16.949050155+00:00 fpga12/2 (192.168.1.113): 26.475\n",
      "\n",
      "Reading into buffer\n",
      "Done.\n",
      "Read 28097 power values\n",
      "Found location in file: 2019-08-27 17:51:22.687451232+00:00 fpga13/0 (192.168.1.105): 26.970\n",
      "\n",
      "Reading into buffer\n",
      "Done.\n",
      "Read 28326 power values\n",
      "Found location in file: 2019-08-27 17:51:21.030832525+00:00 fpga13/1 (192.168.1.104): 25.720\n",
      "\n",
      "Reading into buffer\n",
      "Done.\n",
      "Read 28420 power values\n",
      "Found location in file: 2019-08-27 17:51:07.640404823+00:00 fpga12/0 (192.168.1.110): 25.095\n",
      "\n",
      "Reading into buffer\n",
      "Done.\n",
      "Read 28260 power values\n",
      "Found location in file: 2019-08-27 17:51:54.538199104+00:00 arista (192.168.1.118): 109.185\n",
      "\n",
      "Reading into buffer\n",
      "Done.\n",
      "Read 28218 power values\n",
      "Read baseline\n",
      "Read hc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cpu':          device                ip    power       date_time   exp_time  trial  \\\n",
       " 0      fpga12/1  (192.168.1.115):   27.130 00:00:00.081767 -14.918232      0   \n",
       " 1      fpga12/1  (192.168.1.115):   27.170 00:00:01.140010 -13.859990      0   \n",
       " 2      fpga12/1  (192.168.1.115):   27.150 00:00:02.189545 -12.810454      0   \n",
       " 3      fpga12/1  (192.168.1.115):   27.165 00:00:03.239181 -11.760819      0   \n",
       " 4      fpga12/1  (192.168.1.115):   27.150 00:00:04.160768 -10.839231      0   \n",
       " ...         ...               ...      ...             ...        ...    ...   \n",
       " 12901    arista  (192.168.1.118):  108.855 00:01:10.806564  55.806565      9   \n",
       " 12902    arista  (192.168.1.118):  108.950 00:01:11.857343  56.857343      9   \n",
       " 12903    arista  (192.168.1.118):  108.770 00:01:12.899695  57.899696      9   \n",
       " 12904    arista  (192.168.1.118):  108.825 00:01:13.793356  58.793357      9   \n",
       " 12905    arista  (192.168.1.118):  108.880 00:01:14.841664  59.841665      9   \n",
       " \n",
       "       experiment  \n",
       " 0       baseline  \n",
       " 1       baseline  \n",
       " 2       baseline  \n",
       " 3       baseline  \n",
       " 4       baseline  \n",
       " ...          ...  \n",
       " 12901         hc  \n",
       " 12902         hc  \n",
       " 12903         hc  \n",
       " 12904         hc  \n",
       " 12905         hc  \n",
       " \n",
       " [12906 rows x 7 columns]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_experiment_powers(dict(\n",
    "    cpu = 'data/e2e_output_500k_cpu_hc_11'\n",
    "), 10, ['baseline', 'hc']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
