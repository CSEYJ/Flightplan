From: "NetCompute'18 HotCRP" <noreply@sigcomm18netcompute.hotcrp.com>
Subject: [NetCompute'18] Accepted paper #7 "In-network computing to the rescue of..."
Date: April 30, 2018 at 3:31:53 PM EDT
To: Andre DeHon <andre@acm.org>, Boon Thau Loo <boonloo@seas.upenn.edu>, Hans Giesen <giesen@seas.upenn.edu>, John Sonchack <jsonch@seas.upenn.edu>, Nishanth Prabhu <niprabhu@seas.upenn.edu>, Nik Sultana <nsultana@seas.upenn.edu>, Lei Shi <shilei@seas.upenn.edu>
Cc: xinjin@cs.jhu.edu, chang@barefootnetworks.com
Reply-To: xinjin@cs.jhu.edu, chang@barefootnetworks.com

Dear authors,

The ACM SIGCOMM 2018 Workshop on In-Network Computing (NetCompute'18)
program committee is delighted to inform you that your paper #7 has been
accepted to appear in the conference.

      Title: In-network computing to the rescue of faulty links
    Authors: Hans Giesen (University of Pennsylvania)
             Lei Shi (University of Pennsylvania)
             John Sonchack (University of Pennsylvania)
             Anirudh Chelluri (University of Pennsylvania)
             Nishanth Prabhu (University of Pennsylvania)
             Nik Sultana (University of Pennsylvania)
             Latha Kant (Vencore Labs)
             Anthony J McAuley (Vencore Labs)
             Alexander Poylisher (Vencore Labs)
             André DeHon (University of Pennsylvania)
             Boon Thau Loo (University of Pennsylvania)
 Paper site: https://sigcomm18netcompute.hotcrp.com/paper/7?cap=07aI6XIUnL529w

Your paper was one of 6 accepted out of 11 submissions. Congratulations!

Reviews and comments on your paper are appended to this email. The
submissions site also has the paper's reviews and comments, as well as more
information about review scores.

Contact Xin Jin <xinjin@cs.jhu.edu> and Changhoon Kim
<chang@barefootnetworks.com> with any questions or concerns.

- NetCompute'18 Submissions

Review #7A
===========================================================================

Overall merit
-------------
4. Accept

Reviewer expertise
------------------
4. Expert

Paper summary
-------------
This paper discusses how to leverage in-network computation power on programmable switch to enable FEC on layer-2 for utilizing lossy links.

Comments for author
-------------------
I think this paper is a nice try, despite the current solution seems to be preliminary.

First of all, I think enable FEC on demand makes sense to production networks for elephant flows. A packet loss can kill the performance of a big TCP flow, and ensuring no loss in network is efficient compared with doing it in end hosts.

I appreciate that the authors actually implement this idea with hardware, while the current implementation seems to be impractical because I do not believe a switch should have a FPGA on data plane just for this feature. However, it is interesting to see the limitations of current P4, and I think this work can somehow inspire the design of next generation of programmable ASIC on switch.

Therefore, I think this paper is good for a discussion in the in-network computing workshop.


* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *


Review #7B
===========================================================================

Overall merit
-------------
2. Weak reject

Reviewer expertise
------------------
3. Knowledgeable

Paper summary
-------------
Wharf is a in-switch, per-link FEC mechanism to recover _some_ capacity out of the faulty link. The system consists of a sending proxy, a receiving proxy, and a link monitoring agent. The implementation of encoder on FPGA was reported in evaluation section.

Comments for author
-------------------
This is an interesting idea! As you mentioned, traditionally bad links are turned off completely to avoid undetermined behaviors. Some sort of link level protection is valuable, especially in WAN settings.

However, the paper in its current form feels quite incomplete. Although I understand this is a workshop paper that would not have all details, some critical questions still need to be answered.

- You may be over claiming that you are "able to identify the faulty link directly (Section 1)". To me this is a much more interesting problem than how to correct the packets. The link error detection mechanism is only briefly discussed in Section 3.3 but only with a reference [19]. What types of errors are you interested in? How frequent are they appearing in DC/WAN? Do you actually have an implementation of [19] in your evaluation?

- What happened if you only have one packet at a time? Figure 6 and Section 4.3 seems suggested that at least k packets are needed to generate those parity packets. In reality, packet  arrival has gap between them, so different packet arrival pattern would affect the overall system latency. In the worst case, the sender only sends one packet and nothing else. How would you recover in this case?

- It seems that Xilinx already has RS FEC core (https://www.xilinx.com/support/documentation/ip_documentation/ieee802d3_rs_fec/v2_0/pb028-ieee802d3-rs-fec.pdf) Why implement in your own way from C? Or more generally, what's special about your specific RSE implementation? For me it's OK to use some off-the-shelf FEC algorithm but how/where you use it is much more important.

- It's good to see FPGA encoder implementation. But decoder is not finished yet. The system would be more convincing with a complete implementation.


* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *


Review #7C
===========================================================================

Overall merit
-------------
3. Weak accept

Reviewer expertise
------------------
3. Knowledgeable

Paper summary
-------------
Describes Wharf, which implements an in-network forward error
correction (FEC) scheme using programmable network hardware.

Comments for author
-------------------
Wharf is a system that provides resilience to faulty links,
implemented using in-network processing. The ability to enrich
networks with richer forms of error correction, as well as more exotic
applications such as network coding is a cool idea, and one that is
enabled by new P4-enabled platforms. I think it is worth discussing
this paper at the workshop.

However, the paper is not perfect. Some key assumptions and details
about the design are not described in much depth. And the paper lacks
much discussion of the bigger picture around the opportunities and
limitations associated in-network computation based on coding
theory. In particular, it seems challenging to implement this
functionality in P4 in its current form. There are also ramifications
for throughput and latency that seem fundamental, which raises
questions in related to the "end to end arugment" if not all end hosts
benefit equally from this functionality.

Detailed Comments.

The Introduction spends most of its time discussing the trend toward
in-network computing and various philosophical issues. However, the
description of the approach that underpins Wharf is only described at
a high level. For a specialized workshop, this emphasis could probably
safely be inverted.

I expected to see a discussion of the failure model early in the
paper. However, with the exception of the brief mention of the SIGCOMM
paper by Zhou et al., this assumption is not described precisely
anywhere in the paper.

The Introduction mentions distributed mitigation, but most of the
solution focuses on a sender on one side of a faulty link and a
receiver on the other side. There is a brief discussion of extended
LLDP with information about faulty links, but this isn't discussed
further.

Section 2 makes a distinction between the FEC used by the physical
layer and the FEC used in Wharf based on intent:

the physical-layer FEC helps the link sustain a given capacity over
longer distances, whereas our FEC is intended to mitigate errors that
do not arise because of challenging environmental factors; rather the
errors arise because of physical damage to the link or failing
transceivers

It's unclear why the phsyical-layer FEC couldn't be replaced with a
different code to achieve the same effect?

Section 3.1 and 3.2s are somewhat ophaned from the rest of the
discussion of the design. Perhaps this should be reorganized.

The paper discusses an implementation using Xilinx's SDNet FPGA
platform and experiments using Barefoot's Tofino ASIC. It was somewhat
unclear how the Tofino implements the encoder/decoder components, as
it doesn't provide the ability to process the entire packet. The
division of labor between the two implementations could be made
clearer.

I was interested in Section 5.1.2, which provides evidence about the
potential gains to be had with respect end-to-end performance in a
Clos topology. However, the results seem inconclusive.

Typos:

* Section 3.1 "partitionthe"

